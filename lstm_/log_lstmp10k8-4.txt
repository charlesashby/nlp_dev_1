TRAIN: epoch: 0 - iteration: 0 - acc: 0.0 - loss: 9.49644088745 
TRAIN: epoch: 0 - iteration: 500 - acc: 0.0638125017285 - loss: 6.87552928925 
TRAIN: epoch: 0 - iteration: 1000 - acc: 0.0719375014305 - loss: 6.54500389099 
TRAIN: epoch: 0 - iteration: 1500 - acc: 0.112625002861 - loss: 6.27316856384 
TRAIN: epoch: 0 - iteration: 2000 - acc: 0.140750005841 - loss: 5.92680978775 
TRAIN: epoch: 0 - iteration: 2500 - acc: 0.178625002503 - loss: 5.57469463348 
TRAIN: epoch: 0 - iteration: 3000 - acc: 0.196250006557 - loss: 5.42277908325 
TRAIN: epoch: 0 - iteration: 3500 - acc: 0.221437498927 - loss: 5.15533971786 
TRAIN: epoch: 0 - iteration: 4000 - acc: 0.228062495589 - loss: 5.03124141693 
TRAIN: epoch: 0 - iteration: 4500 - acc: 0.241500005126 - loss: 4.98517560959 
TRAIN: epoch: 0 - iteration: 5000 - acc: 0.251812487841 - loss: 4.83591794968 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k8-4_5000_0/lstmVALID: epoch: 0 - iteration: 5000 - acc: 0.247187495232 
TRAIN: epoch: 0 - iteration: 5500 - acc: 0.262437492609 - loss: 4.75117921829 
TRAIN: epoch: 0 - iteration: 6000 - acc: 0.270437508821 - loss: 4.68686532974 
TRAIN: epoch: 0 - iteration: 6500 - acc: 0.27493751049 - loss: 4.64990615845 
TRAIN: epoch: 0 - iteration: 7000 - acc: 0.286249995232 - loss: 4.54429674149 
TRAIN: epoch: 0 - iteration: 7500 - acc: 0.285937488079 - loss: 4.5408616066 
TRAIN: epoch: 0 - iteration: 8000 - acc: 0.293187499046 - loss: 4.48300552368 
TRAIN: epoch: 0 - iteration: 8500 - acc: 0.298312485218 - loss: 4.43959665298 
TRAIN: epoch: 0 - iteration: 9000 - acc: 0.303375005722 - loss: 4.40292882919 
TRAIN: epoch: 0 - iteration: 9500 - acc: 0.310250014067 - loss: 4.35619020462 
TRAIN: epoch: 0 - iteration: 10000 - acc: 0.31099998951 - loss: 4.29857730865 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k8-4_10000_0/lstmVALID: epoch: 0 - iteration: 10000 - acc: 0.28281250596 
TRAIN: epoch: 0 - iteration: 10500 - acc: 0.312249988317 - loss: 4.29845476151 
TRAIN: epoch: 0 - iteration: 11000 - acc: 0.314249992371 - loss: 4.22861194611 
TRAIN: epoch: 0 - iteration: 11500 - acc: 0.317187488079 - loss: 4.2199139595 
TRAIN: epoch: 0 - iteration: 12000 - acc: 0.331124991179 - loss: 4.17140722275 
TRAIN: epoch: 0 - iteration: 12500 - acc: 0.330624997616 - loss: 4.14994430542 
TRAIN: epoch: 0 - iteration: 13000 - acc: 0.333562493324 - loss: 4.13973236084 
TRAIN: epoch: 0 - iteration: 13500 - acc: 0.340562492609 - loss: 4.11426353455 
TRAIN: epoch: 0 - iteration: 14000 - acc: 0.340999990702 - loss: 4.05841827393 
TRAIN: epoch: 0 - iteration: 14500 - acc: 0.339187502861 - loss: 4.09110546112 
TRAIN: epoch: 0 - iteration: 15000 - acc: 0.338250011206 - loss: 4.04798460007 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k8-4_15000_0/lstmVALID: epoch: 0 - iteration: 15000 - acc: 0.332812488079 
TRAIN: epoch: 0 - iteration: 15500 - acc: 0.346875011921 - loss: 4.03328752518 
TRAIN: epoch: 0 - iteration: 16000 - acc: 0.353249996901 - loss: 4.04953336716 
TRAIN: epoch: 0 - iteration: 16500 - acc: 0.352999985218 - loss: 4.00855922699 
TRAIN: epoch: 0 - iteration: 17000 - acc: 0.351000010967 - loss: 3.99720716476 
TRAIN: epoch: 0 - iteration: 17500 - acc: 0.357625007629 - loss: 3.92947721481 
TRAIN: epoch: 0 - iteration: 18000 - acc: 0.364312499762 - loss: 3.91599941254 
TRAIN: epoch: 0 - iteration: 18500 - acc: 0.364874988794 - loss: 3.88244628906 
TRAIN: epoch: 0 - iteration: 19000 - acc: 0.36875000596 - loss: 3.86083507538 
TRAIN: epoch: 0 - iteration: 19500 - acc: 0.368312507868 - loss: 3.86453342438 
TRAIN: epoch: 0 - iteration: 20000 - acc: 0.369187504053 - loss: 3.84752345085 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k8-4_20000_0/lstmVALID: epoch: 0 - iteration: 20000 - acc: 0.343124985695 
TRAIN: epoch: 0 - iteration: 20500 - acc: 0.372750014067 - loss: 3.82235407829 
TRAIN: epoch: 0 - iteration: 21000 - acc: 0.382499992847 - loss: 3.80157780647 
TRAIN: epoch: 0 - iteration: 21500 - acc: 0.374062508345 - loss: 3.7892563343 
TRAIN: epoch: 0 - iteration: 22000 - acc: 0.376812487841 - loss: 3.80395722389 
TRAIN: epoch: 0 - iteration: 22500 - acc: 0.381500005722 - loss: 3.76012849808 
TRAIN: epoch: 0 - iteration: 23000 - acc: 0.377875000238 - loss: 3.73505401611 
TRAIN: epoch: 0 - iteration: 23500 - acc: 0.392312496901 - loss: 3.68225884438 
TRAIN: epoch: 0 - iteration: 24000 - acc: 0.381437510252 - loss: 3.73484325409 
TRAIN: epoch: 0 - iteration: 24500 - acc: 0.395249992609 - loss: 3.65638542175 
TRAIN: epoch: 0 - iteration: 25000 - acc: 0.386687487364 - loss: 3.72602128983 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k8-4_25000_0/lstmVALID: epoch: 0 - iteration: 25000 - acc: 0.360312491655 
TRAIN: epoch: 0 - iteration: 25500 - acc: 0.394499987364 - loss: 3.61418199539 
TRAIN: epoch: 0 - iteration: 26000 - acc: 0.388749986887 - loss: 3.61009550095 
TRAIN: epoch: 0 - iteration: 26500 - acc: 0.398124992847 - loss: 3.65197300911 
TRAIN: epoch: 0 - iteration: 27000 - acc: 0.399125009775 - loss: 3.61750102043 
TRAIN: epoch: 0 - iteration: 27500 - acc: 0.391874998808 - loss: 3.64601922035 
TRAIN: epoch: 0 - iteration: 28000 - acc: 0.39993751049 - loss: 3.56825232506 
TRAIN: epoch: 0 - iteration: 28500 - acc: 0.403562486172 - loss: 3.5706653595 
TRAIN: epoch: 0 - iteration: 29000 - acc: 0.388875007629 - loss: 3.63881468773 
TRAIN: epoch: 0 - iteration: 29500 - acc: 0.400687485933 - loss: 3.56604480743 
TRAIN: epoch: 0 - iteration: 30000 - acc: 0.40606251359 - loss: 3.52158689499 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k8-4_30000_0/lstmVALID: epoch: 0 - iteration: 30000 - acc: 0.363437503576 
TRAIN: epoch: 0 - iteration: 30500 - acc: 0.405187487602 - loss: 3.55706191063 
TRAIN: epoch: 0 - iteration: 31000 - acc: 0.401687502861 - loss: 3.55283546448 
TRAIN: epoch: 0 - iteration: 31500 - acc: 0.39687499404 - loss: 3.63872694969 
TRAIN: epoch: 0 - iteration: 32000 - acc: 0.389187514782 - loss: 3.70366644859 
TRAIN: epoch: 0 - iteration: 32500 - acc: 0.39862498641 - loss: 3.63543152809 
TRAIN: epoch: 0 - iteration: 33000 - acc: 0.396750003099 - loss: 3.61414217949 
TRAIN: epoch: 0 - iteration: 33500 - acc: 0.402624994516 - loss: 3.60707330704 
TRAIN: epoch: 0 - iteration: 34000 - acc: 0.399874985218 - loss: 3.61456418037 
TRAIN: epoch: 0 - iteration: 34500 - acc: 0.40468749404 - loss: 3.57901573181 
TRAIN: epoch: 0 - iteration: 35000 - acc: 0.408812493086 - loss: 3.55745172501 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k8-4_35000_0/lstmVALID: epoch: 0 - iteration: 35000 - acc: 0.3828125 
TRAIN: epoch: 0 - iteration: 35500 - acc: 0.402500003576 - loss: 3.60177206993 
TRAIN: epoch: 0 - iteration: 36000 - acc: 0.401625007391 - loss: 3.57630562782 
TRAIN: epoch: 0 - iteration: 36500 - acc: 0.412250012159 - loss: 3.50915408134 
TRAIN: epoch: 0 - iteration: 37000 - acc: 0.406500011683 - loss: 3.54805517197 
TRAIN: epoch: 0 - iteration: 37500 - acc: 0.419250011444 - loss: 3.49055576324 
TRAIN: epoch: 0 - iteration: 38000 - acc: 0.40625 - loss: 3.51369929314 
TRAIN: epoch: 0 - iteration: 38500 - acc: 0.410812497139 - loss: 3.5348341465 
TRAIN: epoch: 0 - iteration: 39000 - acc: 0.413312494755 - loss: 3.49010801315 
TRAIN: epoch: 0 - iteration: 39500 - acc: 0.418187499046 - loss: 3.47092580795 
TRAIN: epoch: 0 - iteration: 40000 - acc: 0.422374993563 - loss: 3.43230938911 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k8-4_40000_0/lstmVALID: epoch: 0 - iteration: 40000 - acc: 0.404374986887 
TRAIN: epoch: 0 - iteration: 40500 - acc: 0.423999994993 - loss: 3.40899419785 
TRAIN: epoch: 0 - iteration: 41000 - acc: 0.426375001669 - loss: 3.40119051933 
TRAIN: epoch: 0 - iteration: 41500 - acc: 0.419625014067 - loss: 3.44352841377 
TRAIN: epoch: 0 - iteration: 42000 - acc: 0.418875008821 - loss: 3.43595457077 
TRAIN: epoch: 0 - iteration: 42500 - acc: 0.419499993324 - loss: 3.42541742325 
TRAIN: epoch: 0 - iteration: 43000 - acc: 0.425312489271 - loss: 3.40665411949 
TRAIN: epoch: 0 - iteration: 43500 - acc: 0.424187511206 - loss: 3.40541553497 
TRAIN: epoch: 1 - iteration: 0 - acc: 0.4375 - loss: 3.26197457314 
TRAIN: epoch: 1 - iteration: 500 - acc: 0.416437506676 - loss: 3.40401506424 
TRAIN: epoch: 1 - iteration: 1000 - acc: 0.431499987841 - loss: 3.34921646118 
TRAIN: epoch: 1 - iteration: 1500 - acc: 0.424750000238 - loss: 3.37107610703 
TRAIN: epoch: 1 - iteration: 2000 - acc: 0.420187503099 - loss: 3.36815428734 
TRAIN: epoch: 1 - iteration: 2500 - acc: 0.438125014305 - loss: 3.30081510544 
TRAIN: epoch: 1 - iteration: 3000 - acc: 0.425000011921 - loss: 3.33944678307 
TRAIN: epoch: 1 - iteration: 3500 - acc: 0.439937502146 - loss: 3.24556112289 
TRAIN: epoch: 1 - iteration: 4000 - acc: 0.434187501669 - loss: 3.2543027401 
TRAIN: epoch: 1 - iteration: 4500 - acc: 0.427500009537 - loss: 3.30247807503 
TRAIN: epoch: 1 - iteration: 5000 - acc: 0.433312505484 - loss: 3.23064303398 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k8-4_5000_1/lstmVALID: epoch: 1 - iteration: 5000 - acc: 0.411562502384 
TRAIN: epoch: 1 - iteration: 5500 - acc: 0.442187488079 - loss: 3.21192216873 
TRAIN: epoch: 1 - iteration: 6000 - acc: 0.441500008106 - loss: 3.21761083603 
TRAIN: epoch: 1 - iteration: 6500 - acc: 0.438374996185 - loss: 3.22166395187 
TRAIN: epoch: 1 - iteration: 7000 - acc: 0.447812497616 - loss: 3.1758286953 
TRAIN: epoch: 1 - iteration: 7500 - acc: 0.439312487841 - loss: 3.22274756432 
TRAIN: epoch: 1 - iteration: 8000 - acc: 0.442562490702 - loss: 3.19523692131 
TRAIN: epoch: 1 - iteration: 8500 - acc: 0.441624999046 - loss: 3.20674037933 
TRAIN: epoch: 1 - iteration: 9000 - acc: 0.442187488079 - loss: 3.19388127327 
TRAIN: epoch: 1 - iteration: 9500 - acc: 0.449000000954 - loss: 3.16998434067 
TRAIN: epoch: 1 - iteration: 10000 - acc: 0.44549998641 - loss: 3.14549565315 
VALID: epoch: 1 - iteration: 10000 - acc: 0.40000000596 
TRAIN: epoch: 1 - iteration: 10500 - acc: 0.443187505007 - loss: 3.16177296638 
TRAIN: epoch: 1 - iteration: 11000 - acc: 0.446624994278 - loss: 3.1049888134 
TRAIN: epoch: 1 - iteration: 11500 - acc: 0.448062509298 - loss: 3.11008930206 
TRAIN: epoch: 1 - iteration: 12000 - acc: 0.449250012636 - loss: 3.10190057755 
TRAIN: epoch: 1 - iteration: 12500 - acc: 0.454499989748 - loss: 3.06678557396 
TRAIN: epoch: 1 - iteration: 13000 - acc: 0.453750014305 - loss: 3.09212565422 
TRAIN: epoch: 1 - iteration: 13500 - acc: 0.456812500954 - loss: 3.08274292946 
TRAIN: epoch: 1 - iteration: 14000 - acc: 0.458687514067 - loss: 3.04710888863 
TRAIN: epoch: 1 - iteration: 14500 - acc: 0.458999991417 - loss: 3.0869641304 
TRAIN: epoch: 1 - iteration: 15000 - acc: 0.451124995947 - loss: 3.06626439095 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k8-4_15000_1/lstmVALID: epoch: 1 - iteration: 15000 - acc: 0.418125003576 
TRAIN: epoch: 1 - iteration: 15500 - acc: 0.455687493086 - loss: 3.05103516579 
TRAIN: epoch: 1 - iteration: 16000 - acc: 0.45943748951 - loss: 3.07747936249 
TRAIN: epoch: 1 - iteration: 16500 - acc: 0.458499997854 - loss: 3.02869296074 
TRAIN: epoch: 1 - iteration: 17000 - acc: 0.457749992609 - loss: 3.03478384018 
TRAIN: epoch: 1 - iteration: 17500 - acc: 0.465000003576 - loss: 3.01855897903 
TRAIN: epoch: 1 - iteration: 18000 - acc: 0.464187502861 - loss: 3.00184321404 
TRAIN: epoch: 1 - iteration: 18500 - acc: 0.465624988079 - loss: 2.97620630264 
TRAIN: epoch: 1 - iteration: 19000 - acc: 0.471812486649 - loss: 2.95537924767 
TRAIN: epoch: 1 - iteration: 19500 - acc: 0.466250002384 - loss: 2.97464847565 
TRAIN: epoch: 1 - iteration: 20000 - acc: 0.472187489271 - loss: 2.97094511986 
VALID: epoch: 1 - iteration: 20000 - acc: 0.414375007153 
TRAIN: epoch: 1 - iteration: 20500 - acc: 0.475625008345 - loss: 2.94502496719 
TRAIN: epoch: 1 - iteration: 21000 - acc: 0.473500013351 - loss: 2.95035791397 
TRAIN: epoch: 1 - iteration: 21500 - acc: 0.475250005722 - loss: 2.9448466301 
TRAIN: epoch: 1 - iteration: 22000 - acc: 0.46856251359 - loss: 2.97261333466 
TRAIN: epoch: 1 - iteration: 22500 - acc: 0.473937511444 - loss: 2.93053174019 
TRAIN: epoch: 1 - iteration: 15500 - acc: 0.46893748641 - loss: 2.93072247505 
TRAIN: epoch: 1 - iteration: 16000 - acc: 0.474500000477 - loss: 2.91077256203 
TRAIN: epoch: 1 - iteration: 16500 - acc: 0.479562491179 - loss: 2.91692066193 
TRAIN: epoch: 1 - iteration: 17000 - acc: 0.479750007391 - loss: 2.92148399353 
TRAIN: epoch: 1 - iteration: 17500 - acc: 0.478687494993 - loss: 2.91233706474 
TRAIN: epoch: 1 - iteration: 18000 - acc: 0.478875011206 - loss: 2.87779331207 
TRAIN: epoch: 1 - iteration: 18500 - acc: 0.479999989271 - loss: 2.88320732117 
TRAIN: epoch: 1 - iteration: 19000 - acc: 0.480749994516 - loss: 2.89005565643 
TRAIN: epoch: 1 - iteration: 19500 - acc: 0.486437499523 - loss: 2.85600662231 
TRAIN: epoch: 1 - iteration: 20000 - acc: 0.479375004768 - loss: 2.86872434616 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k8-4_20000_1/lstmVALID: epoch: 1 - iteration: 20000 - acc: 0.421875 
TRAIN: epoch: 1 - iteration: 20500 - acc: 0.485062509775 - loss: 2.86117339134 
TRAIN: epoch: 1 - iteration: 21000 - acc: 0.481249988079 - loss: 2.87218356133 
TRAIN: epoch: 1 - iteration: 21500 - acc: 0.479187488556 - loss: 2.86822223663 
TRAIN: epoch: 1 - iteration: 22000 - acc: 0.482187509537 - loss: 2.84892630577 
TRAIN: epoch: 1 - iteration: 22500 - acc: 0.501062512398 - loss: 2.7793443203 
TRAIN: epoch: 1 - iteration: 23000 - acc: 0.486187487841 - loss: 2.84526181221 
TRAIN: epoch: 1 - iteration: 23500 - acc: 0.48281249404 - loss: 2.84956741333 
TRAIN: epoch: 1 - iteration: 24000 - acc: 0.487562507391 - loss: 2.82255458832 
TRAIN: epoch: 1 - iteration: 24500 - acc: 0.488437503576 - loss: 2.83565759659 
TRAIN: epoch: 1 - iteration: 25000 - acc: 0.488687485456 - loss: 2.83064985275 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k8-4_25000_1/lstmVALID: epoch: 1 - iteration: 25000 - acc: 0.434687495232 
TRAIN: epoch: 1 - iteration: 25500 - acc: 0.492624998093 - loss: 2.8085706234 
TRAIN: epoch: 1 - iteration: 26000 - acc: 0.484687507153 - loss: 2.83568549156 
TRAIN: epoch: 1 - iteration: 26500 - acc: 0.491812497377 - loss: 2.82273650169 
TRAIN: epoch: 1 - iteration: 27000 - acc: 0.494437485933 - loss: 2.8112578392 
TRAIN: epoch: 1 - iteration: 27500 - acc: 0.491062492132 - loss: 2.82118749619 
TRAIN: epoch: 1 - iteration: 28000 - acc: 0.487437486649 - loss: 2.79736804962 
TRAIN: epoch: 1 - iteration: 28500 - acc: 0.497249990702 - loss: 2.75496101379 
TRAIN: epoch: 1 - iteration: 29000 - acc: 0.496499985456 - loss: 2.77556347847 
TRAIN: epoch: 1 - iteration: 29500 - acc: 0.490125000477 - loss: 2.79656791687 
TRAIN: epoch: 1 - iteration: 30000 - acc: 0.491562485695 - loss: 2.77369523048 
VALID: epoch: 1 - iteration: 30000 - acc: 0.425937503576 
TRAIN: epoch: 1 - iteration: 30500 - acc: 0.49206250906 - loss: 2.79706573486 
TRAIN: epoch: 1 - iteration: 31000 - acc: 0.491499990225 - loss: 2.77317881584 
TRAIN: epoch: 1 - iteration: 31500 - acc: 0.501437485218 - loss: 2.74247074127 
TRAIN: epoch: 1 - iteration: 32000 - acc: 0.499374985695 - loss: 2.75213336945 
TRAIN: epoch: 1 - iteration: 32500 - acc: 0.495375007391 - loss: 2.76981043816 
TRAIN: epoch: 1 - iteration: 33000 - acc: 0.494500011206 - loss: 2.79743885994 
TRAIN: epoch: 1 - iteration: 33500 - acc: 0.497249990702 - loss: 2.77024555206 
TRAIN: epoch: 1 - iteration: 34000 - acc: 0.505562484264 - loss: 2.74748182297 
TRAIN: epoch: 1 - iteration: 34500 - acc: 0.503624975681 - loss: 2.75150370598 
TRAIN: epoch: 1 - iteration: 35000 - acc: 0.500187516212 - loss: 2.76018452644 
VALID: epoch: 1 - iteration: 35000 - acc: 0.42812499404 
TRAIN: epoch: 1 - iteration: 35500 - acc: 0.46099999547 - loss: 3.04773545265 
TRAIN: epoch: 1 - iteration: 36000 - acc: 0.466937512159 - loss: 3.03773880005 
TRAIN: epoch: 1 - iteration: 36500 - acc: 0.465062499046 - loss: 3.1023888588 
TRAIN: epoch: 1 - iteration: 37000 - acc: 0.462875008583 - loss: 3.08793258667 
TRAIN: epoch: 1 - iteration: 37500 - acc: 0.462624996901 - loss: 3.0978705883 
TRAIN: epoch: 1 - iteration: 38000 - acc: 0.465687513351 - loss: 3.05101752281 
TRAIN: epoch: 1 - iteration: 38500 - acc: 0.462187498808 - loss: 3.07477545738 
TRAIN: epoch: 1 - iteration: 39000 - acc: 0.472687512636 - loss: 3.01458358765 
TRAIN: epoch: 1 - iteration: 39500 - acc: 0.475499987602 - loss: 3.00500512123 
TRAIN: epoch: 1 - iteration: 40000 - acc: 0.480125010014 - loss: 2.98983979225 
VALID: epoch: 1 - iteration: 40000 - acc: 0.422187507153 
TRAIN: epoch: 1 - iteration: 40500 - acc: 0.467624992132 - loss: 3.04822897911 
TRAIN: epoch: 1 - iteration: 41000 - acc: 0.474375009537 - loss: 3.01370859146 
TRAIN: epoch: 1 - iteration: 41500 - acc: 0.475937485695 - loss: 2.97767782211 
TRAIN: epoch: 1 - iteration: 42000 - acc: 0.473062485456 - loss: 2.98622465134 
TRAIN: epoch: 1 - iteration: 42500 - acc: 0.476062506437 - loss: 2.98267865181 
TRAIN: epoch: 1 - iteration: 43000 - acc: 0.479687511921 - loss: 2.98400688171 
TRAIN: epoch: 1 - iteration: 43500 - acc: 0.475687503815 - loss: 3.01433682442 
TRAIN: epoch: 1 - iteration: 44000 - acc: 0.485249996185 - loss: 2.93342041969 
TRAIN: epoch: 1 - iteration: 44500 - acc: 0.475374996662 - loss: 2.96119618416 
TRAIN: epoch: 1 - iteration: 45000 - acc: 0.479750007391 - loss: 2.97743701935 
VALID: epoch: 1 - iteration: 45000 - acc: 0.426874995232 
TRAIN: epoch: 1 - iteration: 45500 - acc: 0.477187514305 - loss: 2.91520571709 
TRAIN: epoch: 1 - iteration: 46000 - acc: 0.482125014067 - loss: 2.91883230209 
TRAIN: epoch: 1 - iteration: 46500 - acc: 0.477625012398 - loss: 2.95842242241 
TRAIN: epoch: 1 - iteration: 47000 - acc: 0.483187496662 - loss: 2.9274790287 
TRAIN: epoch: 1 - iteration: 47500 - acc: 0.484750002623 - loss: 2.94114160538 
TRAIN: epoch: 1 - iteration: 48000 - acc: 0.481000006199 - loss: 2.91854047775 
TRAIN: epoch: 1 - iteration: 48500 - acc: 0.481687486172 - loss: 2.946611166 
TRAIN: epoch: 1 - iteration: 49000 - acc: 0.481187492609 - loss: 2.90061974525 
TRAIN: epoch: 1 - iteration: 49500 - acc: 0.481375008821 - loss: 2.91436958313 
TRAIN: epoch: 1 - iteration: 50000 - acc: 0.484812498093 - loss: 2.92032384872 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k8-4_50000_1/lstmVALID: epoch: 1 - iteration: 50000 - acc: 0.445625007153 
TRAIN: epoch: 1 - iteration: 50500 - acc: 0.478562504053 - loss: 2.94108057022 
TRAIN: epoch: 1 - iteration: 51000 - acc: 0.480062514544 - loss: 2.91066122055 
TRAIN: epoch: 1 - iteration: 51500 - acc: 0.48425000906 - loss: 2.87055373192 
TRAIN: epoch: 1 - iteration: 52000 - acc: 0.482937514782 - loss: 2.92180943489 
TRAIN: epoch: 1 - iteration: 52500 - acc: 0.482187509537 - loss: 2.90330386162 
TRAIN: epoch: 1 - iteration: 53000 - acc: 0.490312486887 - loss: 2.87559461594 
TRAIN: epoch: 1 - iteration: 53500 - acc: 0.494937509298 - loss: 2.85002565384 
TRAIN: epoch: 1 - iteration: 54000 - acc: 0.490125000477 - loss: 2.87582063675 
TRAIN: epoch: 1 - iteration: 54500 - acc: 0.494875013828 - loss: 2.85066437721 
TRAIN: epoch: 1 - iteration: 55000 - acc: 0.489749997854 - loss: 2.8671901226 
VALID: epoch: 1 - iteration: 55000 - acc: 0.426874995232 
TRAIN: epoch: 1 - iteration: 55500 - acc: 0.491250008345 - loss: 2.82856202126 
TRAIN: epoch: 1 - iteration: 56000 - acc: 0.487687498331 - loss: 2.87185025215 
TRAIN: epoch: 1 - iteration: 56500 - acc: 0.484062492847 - loss: 2.87694692612 
TRAIN: epoch: 1 - iteration: 57000 - acc: 0.485812485218 - loss: 2.95700097084 
TRAIN: epoch: 1 - iteration: 57500 - acc: 0.472187489271 - loss: 3.03019976616 
TRAIN: epoch: 1 - iteration: 58000 - acc: 0.478937506676 - loss: 2.97578716278 
TRAIN: epoch: 1 - iteration: 58500 - acc: 0.48456248641 - loss: 2.94778680801 
TRAIN: epoch: 1 - iteration: 59000 - acc: 0.477687507868 - loss: 2.96184515953 
TRAIN: epoch: 1 - iteration: 59500 - acc: 0.481499999762 - loss: 3.00301265717 
TRAIN: epoch: 1 - iteration: 60000 - acc: 0.481875002384 - loss: 2.98942732811 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k8-4_60000_1/lstmVALID: epoch: 1 - iteration: 60000 - acc: 0.455937504768 
TRAIN: epoch: 1 - iteration: 60500 - acc: 0.481249988079 - loss: 2.97307372093 
TRAIN: epoch: 1 - iteration: 61000 - acc: 0.480937510729 - loss: 2.97933220863 
TRAIN: epoch: 1 - iteration: 61500 - acc: 0.481624990702 - loss: 2.94766592979 
TRAIN: epoch: 1 - iteration: 62000 - acc: 0.481437504292 - loss: 2.97738647461 
TRAIN: epoch: 1 - iteration: 62500 - acc: 0.489687502384 - loss: 2.93081092834 
TRAIN: epoch: 1 - iteration: 63000 - acc: 0.482187509537 - loss: 2.92846608162 
TRAIN: epoch: 1 - iteration: 63500 - acc: 0.495375007391 - loss: 2.88116788864 
TRAIN: epoch: 1 - iteration: 64000 - acc: 0.488499999046 - loss: 2.90044164658 
TRAIN: epoch: 1 - iteration: 64500 - acc: 0.484124988317 - loss: 2.91592073441 
TRAIN: epoch: 1 - iteration: 65000 - acc: 0.491812497377 - loss: 2.91076350212 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k8-4_65000_1/lstmVALID: epoch: 1 - iteration: 65000 - acc: 0.459062486887 
TRAIN: epoch: 1 - iteration: 65500 - acc: 0.485624998808 - loss: 2.86477589607 
TRAIN: epoch: 1 - iteration: 66000 - acc: 0.481499999762 - loss: 2.9226629734 
TRAIN: epoch: 1 - iteration: 66500 - acc: 0.486687511206 - loss: 2.91198539734 
TRAIN: epoch: 1 - iteration: 67000 - acc: 0.491874992847 - loss: 2.89723038673 
TRAIN: epoch: 1 - iteration: 67500 - acc: 0.488875001669 - loss: 2.9166405201 
TRAIN: epoch: 1 - iteration: 68000 - acc: 0.490812510252 - loss: 2.87661528587 
TRAIN: epoch: 1 - iteration: 68500 - acc: 0.494937509298 - loss: 2.86294603348 
TRAIN: epoch: 1 - iteration: 69000 - acc: 0.496250003576 - loss: 2.82457852364 
TRAIN: epoch: 1 - iteration: 69500 - acc: 0.498312503099 - loss: 2.83192062378 
TRAIN: epoch: 1 - iteration: 70000 - acc: 0.496250003576 - loss: 2.86756777763 
VALID: epoch: 1 - iteration: 70000 - acc: 0.448125004768 
TRAIN: epoch: 1 - iteration: 70500 - acc: 0.495999991894 - loss: 2.87912583351 
TRAIN: epoch: 1 - iteration: 71000 - acc: 0.500187516212 - loss: 2.81354594231 
TRAIN: epoch: 1 - iteration: 71500 - acc: 0.494562506676 - loss: 2.8439116478 
TRAIN: epoch: 1 - iteration: 72000 - acc: 0.497750014067 - loss: 2.84941506386 
TRAIN: epoch: 1 - iteration: 72500 - acc: 0.499437510967 - loss: 2.81823730469 
TRAIN: epoch: 1 - iteration: 73000 - acc: 0.499125003815 - loss: 2.82250237465 
TRAIN: epoch: 2 - iteration: 15500 - acc: 0.519187510014 - loss: 2.57637143135 
TRAIN: epoch: 2 - iteration: 16000 - acc: 0.532875001431 - loss: 2.52238726616 
TRAIN: epoch: 2 - iteration: 16500 - acc: 0.534562528133 - loss: 2.50360584259 
TRAIN: epoch: 2 - iteration: 17000 - acc: 0.530687510967 - loss: 2.50782608986 
TRAIN: epoch: 2 - iteration: 17500 - acc: 0.531062483788 - loss: 2.48380899429 
TRAIN: epoch: 2 - iteration: 18000 - acc: 0.533249974251 - loss: 2.44928860664 
TRAIN: epoch: 2 - iteration: 18500 - acc: 0.534874975681 - loss: 2.44011759758 
TRAIN: epoch: 2 - iteration: 19000 - acc: 0.535312473774 - loss: 2.44603013992 
TRAIN: epoch: 2 - iteration: 19500 - acc: 0.540499985218 - loss: 2.41085886955 
TRAIN: epoch: 2 - iteration: 20000 - acc: 0.544687509537 - loss: 2.40409302711 
VALID: epoch: 2 - iteration: 20000 - acc: 0.456250011921 
TRAIN: epoch: 2 - iteration: 20500 - acc: 0.54549998045 - loss: 2.40711784363 
TRAIN: epoch: 2 - iteration: 21000 - acc: 0.545937478542 - loss: 2.4071161747 
TRAIN: epoch: 2 - iteration: 21500 - acc: 0.543749988079 - loss: 2.39108657837 
TRAIN: epoch: 2 - iteration: 22000 - acc: 0.547375023365 - loss: 2.38869333267 
TRAIN: epoch: 2 - iteration: 22500 - acc: 0.557812511921 - loss: 2.31571531296 
TRAIN: epoch: 2 - iteration: 23000 - acc: 0.550437510014 - loss: 2.38159370422 
TRAIN: epoch: 2 - iteration: 23500 - acc: 0.546249985695 - loss: 2.35095405579 
TRAIN: epoch: 2 - iteration: 24000 - acc: 0.547749996185 - loss: 2.3522939682 
TRAIN: epoch: 2 - iteration: 24500 - acc: 0.548812508583 - loss: 2.34894537926 
TRAIN: epoch: 2 - iteration: 25000 - acc: 0.552437484264 - loss: 2.3389647007 
VALID: epoch: 2 - iteration: 25000 - acc: 0.453437507153 
TRAIN: epoch: 2 - iteration: 25500 - acc: 0.556937515736 - loss: 2.31491971016 
