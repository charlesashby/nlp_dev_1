TRAIN: epoch: 0 - iteration: 0 - acc: 0.0 - loss: 9.49962615967 
TRAIN: epoch: 0 - iteration: 500 - acc: 0.0726874992251 - loss: 6.90440034866 
TRAIN: epoch: 0 - iteration: 1000 - acc: 0.112812496722 - loss: 6.41974306107 
TRAIN: epoch: 0 - iteration: 1500 - acc: 0.148874998093 - loss: 6.05499792099 
TRAIN: epoch: 0 - iteration: 2000 - acc: 0.186375007033 - loss: 5.65872478485 
TRAIN: epoch: 0 - iteration: 2500 - acc: 0.207124993205 - loss: 5.46367645264 
TRAIN: epoch: 0 - iteration: 3000 - acc: 0.228874996305 - loss: 5.32180929184 
TRAIN: epoch: 0 - iteration: 3500 - acc: 0.248374998569 - loss: 5.08174657822 
TRAIN: epoch: 0 - iteration: 4000 - acc: 0.264874994755 - loss: 4.9753036499 
TRAIN: epoch: 0 - iteration: 4500 - acc: 0.272062510252 - loss: 4.89826583862 
TRAIN: epoch: 0 - iteration: 5000 - acc: 0.282687485218 - loss: 4.78825283051 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k5-3v1_5000_0/lstmVALID: epoch: 0 - iteration: 5000 - acc: 0.297500014305 
TRAIN: epoch: 0 - iteration: 5500 - acc: 0.293312489986 - loss: 4.71137285233 
TRAIN: epoch: 0 - iteration: 6000 - acc: 0.300000011921 - loss: 4.63503265381 
TRAIN: epoch: 0 - iteration: 6500 - acc: 0.310812503099 - loss: 4.58028793335 
TRAIN: epoch: 0 - iteration: 7000 - acc: 0.322124987841 - loss: 4.46887874603 
TRAIN: epoch: 0 - iteration: 7500 - acc: 0.326750010252 - loss: 4.4703207016 
TRAIN: epoch: 0 - iteration: 8000 - acc: 0.328500002623 - loss: 4.39954471588 
TRAIN: epoch: 0 - iteration: 8500 - acc: 0.339749991894 - loss: 4.35257530212 
TRAIN: epoch: 0 - iteration: 9000 - acc: 0.336874991655 - loss: 4.3485994339 
TRAIN: epoch: 0 - iteration: 9500 - acc: 0.337125003338 - loss: 4.30170917511 
TRAIN: epoch: 0 - iteration: 10000 - acc: 0.34531250596 - loss: 4.25305557251 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k5-3v1_10000_0/lstmVALID: epoch: 0 - iteration: 10000 - acc: 0.332187503576 
TRAIN: epoch: 0 - iteration: 10500 - acc: 0.353624999523 - loss: 4.19491815567 
TRAIN: epoch: 0 - iteration: 11000 - acc: 0.362437486649 - loss: 4.15000486374 
TRAIN: epoch: 0 - iteration: 11500 - acc: 0.356875002384 - loss: 4.17118167877 
TRAIN: epoch: 0 - iteration: 12000 - acc: 0.358937501907 - loss: 4.11879491806 
TRAIN: epoch: 0 - iteration: 12500 - acc: 0.364250004292 - loss: 4.10521507263 
TRAIN: epoch: 0 - iteration: 13000 - acc: 0.371562510729 - loss: 4.0509185791 
TRAIN: epoch: 0 - iteration: 13500 - acc: 0.370750010014 - loss: 4.01971578598 
TRAIN: epoch: 0 - iteration: 14000 - acc: 0.37650001049 - loss: 3.9782307148 
TRAIN: epoch: 0 - iteration: 14500 - acc: 0.374312490225 - loss: 4.01168441772 
TRAIN: epoch: 0 - iteration: 15000 - acc: 0.384000003338 - loss: 3.94303417206 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k5-3v1_15000_0/lstmVALID: epoch: 0 - iteration: 15000 - acc: 0.379062503576 
TRAIN: epoch: 0 - iteration: 15500 - acc: 0.379999995232 - loss: 3.93415975571 
TRAIN: epoch: 0 - iteration: 16000 - acc: 0.383187502623 - loss: 3.98333740234 
TRAIN: epoch: 0 - iteration: 16500 - acc: 0.391499996185 - loss: 3.92336034775 
TRAIN: epoch: 0 - iteration: 17000 - acc: 0.384999990463 - loss: 3.94586896896 
TRAIN: epoch: 0 - iteration: 17500 - acc: 0.386124998331 - loss: 3.94615077972 
TRAIN: epoch: 0 - iteration: 18000 - acc: 0.395875006914 - loss: 3.84730362892 
TRAIN: epoch: 0 - iteration: 18500 - acc: 0.397312492132 - loss: 3.82263374329 
TRAIN: epoch: 0 - iteration: 19000 - acc: 0.389874994755 - loss: 3.86923384666 
TRAIN: epoch: 0 - iteration: 19500 - acc: 0.404624998569 - loss: 3.80780816078 
TRAIN: epoch: 0 - iteration: 20000 - acc: 0.39837500453 - loss: 3.81667733192 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k5-3v1_20000_0/lstmVALID: epoch: 0 - iteration: 20000 - acc: 0.404062509537 
TRAIN: epoch: 0 - iteration: 20500 - acc: 0.40612500906 - loss: 3.79488277435 
TRAIN: epoch: 0 - iteration: 21000 - acc: 0.400750011206 - loss: 3.77320289612 
TRAIN: epoch: 0 - iteration: 21500 - acc: 0.411624997854 - loss: 3.72569298744 
TRAIN: epoch: 0 - iteration: 22000 - acc: 0.407375007868 - loss: 3.74264526367 
TRAIN: epoch: 0 - iteration: 22500 - acc: 0.407937496901 - loss: 3.74004006386 
TRAIN: epoch: 0 - iteration: 23000 - acc: 0.404500007629 - loss: 3.72966170311 
TRAIN: epoch: 0 - iteration: 23500 - acc: 0.408250004053 - loss: 3.71380329132 
TRAIN: epoch: 0 - iteration: 24000 - acc: 0.411875009537 - loss: 3.70753359795 
TRAIN: epoch: 0 - iteration: 24500 - acc: 0.416750013828 - loss: 3.6237885952 
TRAIN: epoch: 0 - iteration: 25000 - acc: 0.415062487125 - loss: 3.67497754097 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k5-3v1_25000_0/lstmVALID: epoch: 0 - iteration: 25000 - acc: 0.414687514305 
TRAIN: epoch: 0 - iteration: 25500 - acc: 0.417562514544 - loss: 3.6438164711 
TRAIN: epoch: 0 - iteration: 26000 - acc: 0.414812505245 - loss: 3.64261412621 
TRAIN: epoch: 0 - iteration: 26500 - acc: 0.425187498331 - loss: 3.6184387207 
TRAIN: epoch: 0 - iteration: 27000 - acc: 0.420062512159 - loss: 3.63963961601 
TRAIN: epoch: 0 - iteration: 27500 - acc: 0.426499992609 - loss: 3.60931968689 
TRAIN: epoch: 0 - iteration: 28000 - acc: 0.433874994516 - loss: 3.57720804214 
TRAIN: epoch: 0 - iteration: 28500 - acc: 0.423687487841 - loss: 3.58277583122 
TRAIN: epoch: 0 - iteration: 29000 - acc: 0.418562501669 - loss: 3.59649419785 
TRAIN: epoch: 0 - iteration: 29500 - acc: 0.424437493086 - loss: 3.55470967293 
TRAIN: epoch: 0 - iteration: 30000 - acc: 0.42962500453 - loss: 3.53727531433 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k5-3v1_30000_0/lstmVALID: epoch: 0 - iteration: 30000 - acc: 0.415312498808 
TRAIN: epoch: 0 - iteration: 30500 - acc: 0.427749991417 - loss: 3.5314848423 
TRAIN: epoch: 0 - iteration: 31000 - acc: 0.425937503576 - loss: 3.58598399162 
TRAIN: epoch: 0 - iteration: 31500 - acc: 0.42193749547 - loss: 3.64265322685 
TRAIN: epoch: 0 - iteration: 32000 - acc: 0.417687505484 - loss: 3.7010576725 
TRAIN: epoch: 0 - iteration: 32500 - acc: 0.419812500477 - loss: 3.67712450027 
TRAIN: epoch: 0 - iteration: 33000 - acc: 0.425749987364 - loss: 3.62220740318 
TRAIN: epoch: 0 - iteration: 33500 - acc: 0.42962500453 - loss: 3.63651609421 
TRAIN: epoch: 0 - iteration: 34000 - acc: 0.42031249404 - loss: 3.63326978683 
TRAIN: epoch: 0 - iteration: 34500 - acc: 0.424625009298 - loss: 3.63603687286 
TRAIN: epoch: 0 - iteration: 35000 - acc: 0.430249989033 - loss: 3.57306861877 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k5-3v1_35000_0/lstmVALID: epoch: 0 - iteration: 35000 - acc: 0.430000007153 
TRAIN: epoch: 0 - iteration: 35500 - acc: 0.435062497854 - loss: 3.5250017643 
TRAIN: epoch: 0 - iteration: 36000 - acc: 0.434374988079 - loss: 3.54415273666 
TRAIN: epoch: 0 - iteration: 36500 - acc: 0.436437487602 - loss: 3.51021456718 
TRAIN: epoch: 0 - iteration: 37000 - acc: 0.431437492371 - loss: 3.54959797859 
TRAIN: epoch: 0 - iteration: 37500 - acc: 0.436687499285 - loss: 3.53479456902 
TRAIN: epoch: 0 - iteration: 38000 - acc: 0.435375005007 - loss: 3.54023623466 
TRAIN: epoch: 0 - iteration: 38500 - acc: 0.432562500238 - loss: 3.50566077232 
TRAIN: epoch: 0 - iteration: 39000 - acc: 0.441500008106 - loss: 3.46364784241 
TRAIN: epoch: 0 - iteration: 39500 - acc: 0.44525000453 - loss: 3.43483972549 
TRAIN: epoch: 0 - iteration: 40000 - acc: 0.440750002861 - loss: 3.47852492332 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k5-3v1_40000_0/lstmVALID: epoch: 0 - iteration: 40000 - acc: 0.433124989271 
TRAIN: epoch: 0 - iteration: 40500 - acc: 0.438499987125 - loss: 3.47101163864 
TRAIN: epoch: 0 - iteration: 41000 - acc: 0.442250013351 - loss: 3.44964933395 
TRAIN: epoch: 0 - iteration: 41500 - acc: 0.440312504768 - loss: 3.47663187981 
TRAIN: epoch: 0 - iteration: 42000 - acc: 0.444124996662 - loss: 3.45461177826 
TRAIN: epoch: 0 - iteration: 42500 - acc: 0.44543749094 - loss: 3.39836835861 
TRAIN: epoch: 0 - iteration: 43000 - acc: 0.446500003338 - loss: 3.40394806862 
TRAIN: epoch: 0 - iteration: 43500 - acc: 0.446062505245 - loss: 3.39017105103 
TRAIN: epoch: 1 - iteration: 0 - acc: 0.5 - loss: 2.97226333618 
TRAIN: epoch: 1 - iteration: 500 - acc: 0.442062497139 - loss: 3.4209151268 
TRAIN: epoch: 1 - iteration: 1000 - acc: 0.441500008106 - loss: 3.42163777351 
TRAIN: epoch: 1 - iteration: 1500 - acc: 0.443312495947 - loss: 3.38552689552 
TRAIN: epoch: 1 - iteration: 2000 - acc: 0.450500011444 - loss: 3.33992266655 
TRAIN: epoch: 1 - iteration: 2500 - acc: 0.452562510967 - loss: 3.32806420326 
TRAIN: epoch: 1 - iteration: 3000 - acc: 0.452312499285 - loss: 3.37642717361 
TRAIN: epoch: 1 - iteration: 3500 - acc: 0.451062500477 - loss: 3.30960226059 
TRAIN: epoch: 1 - iteration: 4000 - acc: 0.453687489033 - loss: 3.32501673698 
TRAIN: epoch: 1 - iteration: 4500 - acc: 0.451750010252 - loss: 3.32379007339 
TRAIN: epoch: 1 - iteration: 5000 - acc: 0.456187486649 - loss: 3.27974581718 
saving model: /run/media/ashbylepoc/ff112aea-f91a-4fc7-a80b-4f8fa50d41f3/tmp/data/nlp_dev_1/checkpoints_hist_lstm/lstmp10k5-3v1_5000_1/lstmVALID: epoch: 1 - iteration: 5000 - acc: 0.525624990463 
TRAIN: epoch: 1 - iteration: 5500 - acc: 0.456250011921 - loss: 3.25869488716 
TRAIN: epoch: 1 - iteration: 6000 - acc: 0.457937508821 - loss: 3.26737761497 
TRAIN: epoch: 1 - iteration: 6500 - acc: 0.465874999762 - loss: 3.26614785194 
TRAIN: epoch: 1 - iteration: 7000 - acc: 0.461250007153 - loss: 3.24055528641 
TRAIN: epoch: 1 - iteration: 7500 - acc: 0.461937487125 - loss: 3.23514509201 
TRAIN: epoch: 1 - iteration: 8000 - acc: 0.462187498808 - loss: 3.21511030197 
TRAIN: epoch: 1 - iteration: 8500 - acc: 0.465812504292 - loss: 3.2023870945 
TRAIN: epoch: 1 - iteration: 9000 - acc: 0.460562497377 - loss: 3.2320432663 
TRAIN: epoch: 1 - iteration: 9500 - acc: 0.46081250906 - loss: 3.2087059021 
TRAIN: epoch: 1 - iteration: 10000 - acc: 0.463250011206 - loss: 3.20588493347 
VALID: epoch: 1 - iteration: 10000 - acc: 0.484375 
TRAIN: epoch: 1 - iteration: 10500 - acc: 0.472937494516 - loss: 3.16235399246 
TRAIN: epoch: 1 - iteration: 11000 - acc: 0.470874994993 - loss: 3.15645813942 
TRAIN: epoch: 1 - iteration: 11500 - acc: 0.463874995708 - loss: 3.19430732727 
TRAIN: epoch: 1 - iteration: 12000 - acc: 0.471625000238 - loss: 3.15150737762 
TRAIN: epoch: 1 - iteration: 12500 - acc: 0.471125006676 - loss: 3.15888881683 
TRAIN: epoch: 1 - iteration: 13000 - acc: 0.473562508821 - loss: 3.12868952751 
TRAIN: epoch: 1 - iteration: 13500 - acc: 0.473625004292 - loss: 3.1151535511 
TRAIN: epoch: 1 - iteration: 14000 - acc: 0.478312492371 - loss: 3.08387112617 
TRAIN: epoch: 1 - iteration: 14500 - acc: 0.470812499523 - loss: 3.12238907814 
TRAIN: epoch: 1 - iteration: 15000 - acc: 0.484124988317 - loss: 3.07405948639 
VALID: epoch: 1 - iteration: 15000 - acc: 0.490937501192 
TRAIN: epoch: 1 - iteration: 15500 - acc: 0.476000010967 - loss: 3.09462881088 
TRAIN: epoch: 1 - iteration: 16000 - acc: 0.477687507868 - loss: 3.1240093708 
TRAIN: epoch: 1 - iteration: 16500 - acc: 0.486937493086 - loss: 3.0696284771 
TRAIN: epoch: 1 - iteration: 17000 - acc: 0.476875007153 - loss: 3.112449646 
TRAIN: epoch: 1 - iteration: 17500 - acc: 0.472124993801 - loss: 3.12181401253 
TRAIN: epoch: 1 - iteration: 18000 - acc: 0.483000010252 - loss: 3.03643202782 
TRAIN: epoch: 1 - iteration: 18500 - acc: 0.487062513828 - loss: 3.02903032303 
TRAIN: epoch: 1 - iteration: 19000 - acc: 0.481750011444 - loss: 3.06651329994 
TRAIN: epoch: 1 - iteration: 19500 - acc: 0.488937497139 - loss: 3.0330991745 
TRAIN: epoch: 1 - iteration: 20000 - acc: 0.480312496424 - loss: 3.05781531334 
VALID: epoch: 1 - iteration: 20000 - acc: 0.517499983311 
TRAIN: epoch: 1 - iteration: 20500 - acc: 0.491187512875 - loss: 3.05297112465 
TRAIN: epoch: 1 - iteration: 21000 - acc: 0.484937489033 - loss: 3.03434967995 
TRAIN: epoch: 1 - iteration: 21500 - acc: 0.492437511683 - loss: 2.994171381 
TRAIN: epoch: 1 - iteration: 22000 - acc: 0.489250004292 - loss: 3.02707433701 
TRAIN: epoch: 1 - iteration: 22500 - acc: 0.490249991417 - loss: 3.02796578407 
TRAIN: epoch: 1 - iteration: 23000 - acc: 0.487937510014 - loss: 3.012611866 
TRAIN: epoch: 1 - iteration: 23500 - acc: 0.490249991417 - loss: 3.01341128349 
TRAIN: epoch: 1 - iteration: 24000 - acc: 0.4921875 - loss: 3.0172894001 
TRAIN: epoch: 1 - iteration: 24500 - acc: 0.497312486172 - loss: 2.93217921257 
TRAIN: epoch: 1 - iteration: 25000 - acc: 0.492624998093 - loss: 2.98241591454 
VALID: epoch: 1 - iteration: 25000 - acc: 0.502187490463 
TRAIN: epoch: 1 - iteration: 25500 - acc: 0.492875009775 - loss: 2.97019743919 
TRAIN: epoch: 1 - iteration: 26000 - acc: 0.493874996901 - loss: 2.97580695152 
TRAIN: epoch: 1 - iteration: 26500 - acc: 0.497500002384 - loss: 2.9470975399 
TRAIN: epoch: 1 - iteration: 27000 - acc: 0.497062504292 - loss: 2.96521234512 
TRAIN: epoch: 1 - iteration: 27500 - acc: 0.50137501955 - loss: 2.95422911644 
TRAIN: epoch: 1 - iteration: 28000 - acc: 0.502937495708 - loss: 2.93930006027 
TRAIN: epoch: 1 - iteration: 28500 - acc: 0.498562514782 - loss: 2.92299771309 
TRAIN: epoch: 1 - iteration: 29000 - acc: 0.494062513113 - loss: 2.93534326553 
TRAIN: epoch: 1 - iteration: 29500 - acc: 0.499187499285 - loss: 2.9322271347 
TRAIN: epoch: 1 - iteration: 30000 - acc: 0.503312528133 - loss: 2.90191626549 
VALID: epoch: 1 - iteration: 30000 - acc: 0.488750010729 
TRAIN: epoch: 1 - iteration: 30500 - acc: 0.50150001049 - loss: 2.90139007568 
TRAIN: epoch: 1 - iteration: 31000 - acc: 0.498374998569 - loss: 2.96147561073 
TRAIN: epoch: 1 - iteration: 31500 - acc: 0.495000004768 - loss: 3.00024747849 
TRAIN: epoch: 1 - iteration: 32000 - acc: 0.494125008583 - loss: 3.02525043488 
TRAIN: epoch: 1 - iteration: 32500 - acc: 0.486312508583 - loss: 3.03235340118 
TRAIN: epoch: 1 - iteration: 33000 - acc: 0.496812492609 - loss: 2.98687815666 
TRAIN: epoch: 1 - iteration: 33500 - acc: 0.503125011921 - loss: 2.99234485626 
TRAIN: epoch: 1 - iteration: 34000 - acc: 0.495624989271 - loss: 2.99928307533 
TRAIN: epoch: 0 - iteration: 0 - acc: 0.5 - loss: 3.00662326813 
TRAIN: epoch: 0 - iteration: 500 - acc: 0.434937506914 - loss: 3.45467376709 
TRAIN: epoch: 0 - iteration: 1000 - acc: 0.438437491655 - loss: 3.44820427895 
TRAIN: epoch: 0 - iteration: 1500 - acc: 0.440124988556 - loss: 3.4113240242 
